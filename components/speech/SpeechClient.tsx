"use client";

import { useEffect, useRef, useState } from "react";
import Lottie from "lottie-react";
import { Mic } from "lucide-react";
import idleAnim from "@/src/assets/lotties/idle.json";
import speekAnim from "@/src/assets/lotties/speak.json";
import happyAnim from "@/src/assets/lotties/happy.json";
import sadAnim from "@/src/assets/lotties/sad.json";
import heartAnim from "@/src/assets/lotties/heart.json";
import awkwardAnim from "@/src/assets/lotties/awkward.json";
import surprisedAnim from "@/src/assets/lotties/surprised.json";
import angryAnim from "@/src/assets/lotties/angry.json";
import { useChatHistoryManager } from "@/hooks/useChatHistoryManager";
import { redirect, useRouter } from "next/navigation";
import { getDiary, getOrCreateDiaryId } from "@/data/diary";
import { format } from "date-fns";

type MicStatus =
  | "idle"
  | "neutral"
  | "happy"
  | "sad"
  | "heartwarming"
  | "awkward"
  | "surprised"
  | "angry";

export default function SpeechClient({
  userId,
  DiaryId,
}: {
  userId: string;
  DiaryId: string;
}) {
  const [transcript, setTranscript] = useState("");
  const [status, setStatus] = useState<MicStatus>("idle");
  const { history, addMessages } = useChatHistoryManager(DiaryId);
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const isRecordingRef = useRef(false);
  const hasProcessedRef = useRef(false);
  const lottieRef = useRef<any>(null);
  const router = useRouter();

  const handleDrawDiary = async () => {
    const ttsForm = new FormData();
    ttsForm.append(
      "reply",
      "ì˜¤ëŠ˜ ëŒ€í™”ë„ ë„ˆë¬´ ì¦ê±°ì› ì–´ìš”, ë‹¤ìŒì— ë˜ ê°™ì´ ëŒ€í™”í•´ìš”!"
    );
    setStatus("happy");
    const ttsRes = await fetch("/api/googletts", {
      method: "POST",
      body: ttsForm,
    });

    const { buffer } = await ttsRes.json();
    const audio = new Audio(`data:audio/mp3;base64,${buffer}`);
    audio.play();

    audio.onended = async () => {
      console.log(DiaryId);

      try {
        const form = new FormData();
        form.append("diaryId", DiaryId);
        form.append("history", JSON.stringify(history));

        const res = await fetch("/api/diary/generate", {
          method: "POST",
          body: form,
        });

        const { spokenSummary } = await res.json();
        console.log(spokenSummary);

        const imageForm = new FormData();
        imageForm.append("spokenSummary", spokenSummary);
        imageForm.append("diaryId", DiaryId);
        imageForm.append("userId", userId);
        const date = await fetch("/api/diary/image", {
          method: "POST",
          body: imageForm,
        });

        // ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™ (ë‹¤ì´ì–´ë¦¬ ë‚ ì§œì™€ ì‚¬ìš©ì IDë¥¼ ì‚¬ìš©)
        const dateStr = format(new Date(history[0].createdAt), "yyyy-MM-dd"); // ë˜ëŠ” ì„œë²„ì—ì„œ ë°›ì€ ë‚ ì§œ ì‚¬ìš©

        console.log(dateStr);
        router.push(`/diary/${userId}/${dateStr}`); // ë‚ ì§œ ê²½ë¡œë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸

        // ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™ <<
      } catch (e) {
        console.error("ê·¸ë¦¼ì¼ê¸° ìƒì„± ì‹¤íŒ¨:", e);
        alert("ê·¸ë¦¼ì¼ê¸°ë¥¼ ë§Œë“œëŠ” ì¤‘ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”.");
      }
    };
  };

  const getAnimation = () => {
    switch (status) {
      case "neutral":
        return speekAnim;
      case "happy":
        return happyAnim;
      case "sad":
        return sadAnim;
      case "heartwarming":
        return heartAnim;
      case "awkward":
        return awkwardAnim;
      case "surprised":
        return surprisedAnim;
      case "angry":
        return angryAnim;
      case "idle":
      default:
        return idleAnim;
    }
  };

  useEffect(() => {
    const SpeechRecognition =
      window.SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) {
      alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = "ko-KR";
    recognition.interimResults = true;
    recognition.continuous = false;

    recognition.onstart = () => {
      isRecordingRef.current = true;
    };

    recognition.onend = () => {
      isRecordingRef.current = false;
    };

    recognition.onresult = async (event: SpeechRecognitionEvent) => {
      if (hasProcessedRef.current) return;

      let finalText = "";
      let isFinal = false;

      for (let i = event.resultIndex; i < event.results.length; i++) {
        finalText += event.results[i][0].transcript;
        if (event.results[i].isFinal) isFinal = true;
      }

      setTranscript(finalText);

      if (!isFinal) return;
      hasProcessedRef.current = true;

      setStatus("responding");

      try {
        const chatForm = new FormData();
        chatForm.append("text", finalText);
        chatForm.append("history", JSON.stringify(history));

        const chatRes = await fetch("/api/chat", {
          method: "POST",
          body: chatForm,
        });

        const { result } = await chatRes.json();

        // âœ… JSON ì•ˆì „ íŒŒì‹±
        let parsed;
        try {
          const match = result.match(/\{[\s\S]*\}/);
          if (match) parsed = JSON.parse(match[0]);
        } catch (e) {
          console.warn("JSON íŒŒì‹± ì‹¤íŒ¨:", e);
        }

        const fallbackReply = result; // ê·¸ëƒ¥ í…ìŠ¤íŠ¸ì¼ ë•Œ ì“¸ ëŒ€ì²´ ì‘ë‹µ

        const reply = parsed?.reply || fallbackReply;
        const emotion = parsed?.emotion || "neutral";
        const risk = parsed?.risk ?? 1;

        const ttsForm = new FormData();
        ttsForm.append("reply", reply);

        const ttsRes = await fetch("/api/googletts", {
          method: "POST",
          body: ttsForm,
        });

        const { buffer } = await ttsRes.json();
        const audio = new Audio(`data:audio/mp3;base64,${buffer}`);
        audio.play();

        setStatus(emotion as MicStatus);
        audio.onended = () => {
          setTimeout(() => setStatus("idle"), 300);
          const now = new Date().toISOString();
          addMessages([
            {
              role: "user",
              content: finalText,
              createdAt: now,
              emotion,
              risk,
            },
            {
              role: "assistant",
              content: reply,
              createdAt: now,
              emotion,
              risk,
            },
          ]);
        };
      } catch (error) {
        console.error(error);
        setStatus("idle");
      }
    };

    recognition.onerror = (e: any) => {
      console.error(e);
      setStatus("idle");
    };

    recognitionRef.current = recognition;
  }, [history]);

  const startRecognition = () => {
    if (!recognitionRef.current) return;
    if (isRecordingRef.current) return;

    try {
      recognitionRef.current.start();
      hasProcessedRef.current = false;
    } catch (err: any) {
      if (err.name === "InvalidStateError") {
        console.warn("ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.");
      } else {
        console.error("startRecognition ì˜¤ë¥˜:", err);
      }
    }
  };

  const stopRecognition = () => {
    if (!recognitionRef.current || !isRecordingRef.current) return;
    recognitionRef.current.stop();
  };

  return (
    <div className="relative h-screen w-full bg-gray-50">
      {/* ì• ë‹ˆë©”ì´ì…˜ */}
      <div className="absolute top-1/2 -translate-y-1/2 left-1/2 -translate-x-1/2 w-96 aspect-auto ">
        <Lottie
          lottieRef={lottieRef}
          animationData={getAnimation()}
          loop
          autoplay
        />
      </div>

      {/* ì¸ì‹ëœ í…ìŠ¤íŠ¸ */}
      <div className="absolute bottom-32 left-1/2 -translate-x-1/2 bg-white px-4 py-2 rounded shadow">
        {transcript ? (
          <p className="text-gray-800 text-sm flex">
            <span>ğŸ—£ï¸</span> {transcript}
          </p>
        ) : (
          <p className="text-gray-400 text-sm">
            ë²„íŠ¼ì„ ê¾¹ ëˆ„ë¥´ë©´ ì¸ì‹ì´ ì‹œì‘ë©ë‹ˆë‹¤
          </p>
        )}
      </div>

      {/* ë§ˆì´í¬ ë²„íŠ¼ */}
      <div className="fixed bottom-10 left-1/2 -translate-x-1/2">
        <button
          className="p-4 bg-red-500 text-white rounded-full shadow-md active:scale-95 transition"
          onMouseDown={startRecognition}
          onMouseUp={stopRecognition}
          onMouseLeave={stopRecognition}
          onTouchStart={startRecognition}
          onTouchEnd={stopRecognition}
        >
          <Mic className="w-8 h-8" />
        </button>
      </div>

      {history.length >= 0 && (
        <div className="fixed bottom-20 left-1/2 -translate-x-1/2 z-50">
          <button
            onClick={handleDrawDiary}
            className="px-5 py-3 bg-green-600 text-white rounded-full shadow-lg hover:bg-green-700 transition animate-pulse"
          >
            ğŸ“¸ ì§€ê¸ˆê¹Œì§€ ì´ì•¼ê¸°ë¡œ ê·¸ë¦¼ì¼ê¸° ë§Œë“¤ê¸°
          </button>
        </div>
      )}
    </div>
  );
}
